<aside>
💡 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고 뒤이은 요청이 보다 빨리 처리될 수 
있도록 하는 저장소

</aside>

> 애플리케이션의 성능은 데이터베이스를 얼마나 자주 호출 하느냐에 크게 좌우되는데, 캐시는 그런 문제를 
완화할 수 있음
> 

- 캐시 계층
    
    <aside>
    💡 캐시 계층 (cache tier)은 데이터가 잠시 보관되는 곳으로 데이터베이스보다 훨씬 빠름
    
    </aside>
    
    - 별도의 캐시 계층을 두면 성능이 개선될 뿐만 아니라 데이터베이스의 부하를 줄일 수 있고,
    캐시 계층의 규모를 독립적으로 확장시키는 것도 가능해짐.
    - 요청을 받은 웹 서버는 캐시에 응답이 저장되어 있는지를 봄
    - 만일 저장되어 있다면 해당 데이터를 클라이언트에 반환
    - 없는 경우에는 데이터베이스 질의를 통해 데이터를 찾아 캐시에 저장한 뒤 클라이언트에 반환
    - 이러한 전략을 읽기 주도형 캐시 전략(read-through caching strategy)라고 함
        - ✅ 어떤 캐시 전략이 있을까?
            - Write-Trough Caching
                - 데이터를 캐시와 백엔드 저장소 동시에 쓰는 방식
                - 이 전략은 읽기 주도형 캐시 전략과 함께 사용되며, 쓰기 연산 시 데이터 일관성을 보장함
                - 데이터가 업데이트 되거나 새로운 데이터가 추가될 때, 즉시 캐시와 백엔드 저장소에 반영되므로 데이터 일관성을 유지할 수 있음
            - Write-Back(Write-Behind)Caching
                - Write-back 또는 Write-behind 캐싱 전략은 쓰기 연산을 먼저 캐시에만 수행하고, 나중에 변경된 내용을 백엔드 저장소에 비 동기적으로 반영하는 방식
                - 쓰기 성능을 크게 향상시킬 수 있지만, 캐시 시스템에 장애가 발생할 경우 데이터 손실이 큼
            - Cache-Asied(Lazy Loading)
                - 데이터 요청 시 캐시에서 먼저 데이터를 찾고, 만약 캐시에 없을 경우에만 백엔드 데이터 소스에서 데이터를 조회하여 응답하고, 이후 캐시에 데이터를 저장하는 방식
                - 읽기 주도형 캐시와 다르게 데이터를 요청하는 시점에만 캐시를 업데이트 함

- 캐시 사용 시 유의할 점
    - 캐시는 어떤 상황에 바람직한가?
        - 데이터 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어난다면 고려해볼 만 함
    - 어떤 데이터를 캐시에 두어야 하는가?
        - 캐시는 데이터를 휘발성 메모리에 두므로, 영속적으로 보관할 데이터를 캐시에 두는 것은 바람직하지 않음
        - 중요한 데이터는 지속적 저장소(persistent data store)에 두어야 함
    - 캐시에 보관된 데이터는 어떻게 만료(expire)되는가?
        - 만료된 데이터는 캐시에서 삭제되어야 함
        - 만료 정책이 없으면 데이터는 캐시에 계속 남게 됨
        - 만료 기한이 너무 짧으면 데이터를 너무 자주 읽게 되어 역할을 잘 수행해 낼 수 없으며,
        너무 긴 경우에는 원본과 차이가 날 가능성이 높아지므로 적정한 만료 기한을 선정해야함
    - 일관성(Consistency)
        - 일관성은 데이터 저장소의 원본과 캐시 내의 사본이 같은지 여부
        - 저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우 이 일관성은 깨질 수 있음
        - 여러 지역에 걸쳐 시스템을 확장해 나가는 경우 캐시와 저장소 사이의 일관성을 유지하는 것은 어려운 문제가 됨
    - 장애에 대해 어떻게 처리할 것인가?
        - 캐시 서버를 한 대만 두는 경우 해당 서버는 단일 장애 지점(Single Point Of Failure, SPOF)이 되어버릴 가능성이 있음
        - SPOF를 피하기 위해서는 여러 지역에 걸쳐 캐시 서버를 분산시켜야 함
    - 캐시 메모리는 얼마나 크게 잡을 것인가?
        - 캐시 메모리가 너무 작으면 엑세스 패턴에 따라서는 데이터가 너무 자주 캐시에서 밀려나버려 캐시의 성능이 떨어지게 됨
        - 캐시 메모리를 과할당 하여 캐시에 보관될 데이터가 갑자기 늘어났을 때 생길 문제도 방지할 수 있음
    - 데이터 방출 정책은 무엇인가?
        - 캐시가 가득 찬 경우 추가로 캐시에 데이터를 넣기 위해 기존 데이터를 내보내야 함
        - 이것을 캐시 데이터 방출 정책이라 함
        - 가장 널리 쓰이는 방식은 LRU- 마지막으로 사용된 시점이 가장 오래된 데이터를 내보내는 정책
            - ✅ 어떤 데이터 방출 정책이 있을까?
                
                <aside>
                💡 캐시할 데이터 종류, 크기, 엑세스 패턴에 맞는 캐시 전략을 선택
                효과적인 캐싱 전략을 사용하면 자주 사용되는 데이터에 대한 접근 속도를 높이고 서버의 부하를 줄이며, 사용자 경험을 개선할 수 있음
                
                </aside>
                
                - LRU(Least Recently Used)
                    - LRU 전략은 가장 오래전에 사용된 항목들을 캐시에서 제고함
                    - 가장 최근에 사용되지 않은 항목부터 순서대로 대체되는 방식
                    - 이 방식은 가장 자주 사용되는 데이터를 캐시에 유지하려는 목적에 적합
                - LFU(Least Frequently Used)
                    - 사용 빈도가 가장 낮은 항목을 캐시에서 제거
                    - 사용 빈도를 기반으로 중요한 데이터를 캐시에 유지하려는 경우에 적합
                    - 오랜 기간 동안 자주 사용되는 데이터를 캐시에 보관하는데 유용
                - FIFO(First In, First Out)
                    - 캐시에 가장 먼저 들어온 데이터를 가장 먼저 제거
                    - 캐시의 크기가 고정되어있고, 캐시된 데이터가 시간 순서대로만 유용한 특정 애플리케이션에서 사용
                - Time-to-Live(TTL)
                    - 데이터를 캐시에 저장할 때 유효 시간을 설정
                    - 설정된 시간이 지나면, 해당 데이터는 자동으로 캐시에서 제거
                    - 데이터가 일정 시간 동안만 유효하거나 변동성이 큰 경우에 적합
