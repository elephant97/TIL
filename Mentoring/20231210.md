# 20231210(3회차) 멘토링 내용 정리📒
==> 다시 볼 부분은 💡로 표시

### Enum 
* enum은 clone() 메서드의 사용이 막혀있다
* 상속을 하지 못한다.

### 싱글턴 패턴이란?
* 생성자가 여러 차례 호출되더라도 실제로 생성되는 객체는 하나이고 최초 생성 이후에 호출된 생성자는 최초의 생성자가 생성한 객체를 리턴하는 것
* DBCP(DataBase Connection Pool)과 같은 상황에서 많이 사용
* Enum을 객체로 여러번 생성하더라도 == 비교가 같은것은 Enum이 싱글턴 패튼으로 이루어져있기 때문이다.

### unmodifiable Collection
> collection을 Collection.unmodifiableList();로 생성하면 해당 메소드에서 리턴되는 컬렉션은 **Read Only** 용도로만 사용할 수 있으며,    
> 수정하려는 메소드 (set(), add(), addAll())를 호출하면 **UnsupportedOperationException** 이 발생함.
* **immutable과의 차이는 무엇인가?**
  * unmodifiable은 원본 컬렉션으로의 수정 메소드를 호추할 수 없지만 **원본 리스트 자체가 수정되지 않도록 보장해주지는 않는다.**
    > 'Collection.unmodifiableList()' 메소드로 리턴받은 레퍼런스 이외의 다른 레퍼런스로는 리스트를 수정할 수 있음
  * immutable하다고 한다면 어떤 레퍼런스를 이용해서라도 수정할 수 없어야 함 따라서 unmodifiable은 immutable을 만족하지 않음.
  * 기존에 존재하는 컬렉션을 immutable하게 만들 기 위해서는 기존 컬렉션의 데이터를 다른 새로운 컬렉션으로 복사 한 다음 새로운 컬렉션으로의 수정(modify)접근을 제한하는게 일반적
  ```java
    List<String> immutableList = Collections.unmodifiableList(new ArrayList<String>(list));  // 기존 객체를 바로 넣으면 shallow copy에 해당하여 복제 객체에도 영향을 미치므로
  ```
  * immutable역시 copyOf를 사용해서 만든다면 객체의 원본 수정은 막을 수 없다 // shallow copy에 해당
  ```java
    List<Integer> immutableUserIds = ImmutableList.copyOf(originUserIds);
  ```
  * 완전한 불변 객체로 만들려면 copyOf가 아닌 ImmutableList.of()로 리스트를 생성 해야함.
  ```java
    List<Integer> userIds = ImmutableList.of(1, 2);
  ```
* java9 이후로 List.of() 정적 팩토리 메서드로 불변 객체를 만들 수 있다.(java.util.List)
```java
  List<Integer> userIds = List.of(1, 2);
```

### byte code와 기계어는 무엇이며, 어떤 차이가 있는가?
* byte code (가상머신에서 실행되기 위한 중간 언어) 
  * 컴퓨터 프로그램을 실행하기 위한 중간 단계의 이진 형식 코드      
  * Java는 컴파일러에 의해 소스코드를 바이트코드로 변환하고 그 후에 바이트 코드를 해당 플랫폼에서 실행 가능한 기계어로 변환하여 실행함.
  * byte code는 특정 하드웨어에 의존하지 않고, 특정 플랫폼에서 실행될 수 있도록 설계된 중간 언어.
  * 바이트 코드는 일반적으로 가산 머신(JVM)에서 실행되며, 기계어에 비해 추상화 수준이 높아 이식성이 우수하며 한번의 컴파일로 여러 플랫폼에서 실행될 수 있습니다.
* 기계어 (특정한 하드웨어 아키텍처에서 직접 실행되는 이진 형태 코드)
  * 프로세서가 직접 이해하고 실행할 수 있는 명령어로 구성되어있음.
  * 다양한 하드웨어 아키텍쳐에는 각각 다른 기계어가 존재함.
  * 소프트웨어가 특정 하드웨어에서 동작하려면 해당 하드웨어의 기계어로 컴파일 되어야 함.

### 컴파일러 vs 인터프리터 
> 컴파일러와 인터프리터 모두 high-level language를 machine language로 번역한다.      
* 컴파일러
  > 컴파일러는 소스코드(high-level language로 작성) 전체를 링커 등을 통해 한번에 번역하여 목적파일(기계어로 작성)로 만들어 메모리 상에 적재한다.       
  > 소스코드 전체를 컴퓨터 프로세서가 실행할 수 있도록 바로 기계어로 번환한다.       
  > 컴파일러는 전체 소스코드를 변환 한 뒤 에러를 보고함.   
  * 장점
    * 0과 1로된 기계어로 번역되기 때문에 프로그램의 코드가 유출되지 않는다.
    * 컴파일 에러와 관련된 에러를 초기에 발견할 수 있다.
    * 빠르게 실행 가능하기 때문에 효율적임
  * 단점
    * 코드를 수정하면 컴파일 다시해야함
    * 특정 시스템에서 만들어진 실행 파일이 다른 시스템에서는 실행되지 않는 경우가 많다.
* 인터프리터
  > 소스코드를 한 행씩 중간 코드((intermediate code)로 번역 후 이를 각 행마다 실행한다.       
  > 각 행마다 실행하는 도중 에러가 보고되면 이후 작성된 코드를 살펴보지 않으며, 이는 보안적인 관점에서 도움이 된다.
  * **장점**
    * 메모리를 사용하지 않음
    * 시스템 간의 이식성이 뛰어나다
    * 전체 코드를 다시 컴파일 할 필요가 없기 때문에 코드 수정에 용이
  * **단점**
    * 매번 번역과정을 거쳐야하기 때문에 실행 속도가 컴파일러에 비해 느림
    * 중간 코드로 해석되기 때문에 프로그램의 코드가 유출될 수 있음. 
    
### JIT컴파일러 (Just-In-Time compilation) 
> **동적 변역을 하며 프로그램을 실제 실행하는 시점에 기계어로 번역하는 컴파일 기법**
> 자바는 코드를 실행하기 위해서 바이트코드로 컴파일 하는 과정과 바이트 코드를 인터프리트 하는 과정을 거쳐야 하기 대문에 컴파일 과정만 필요한
> 다른 프로그래밍 언어보다 느리며, 인터프리터는 컴파일러보다 느리기 때문에 성능 문제가 발생하여, 이러한 문제를 개선하기 위해 JIT 컴파일러가 나옴
* 실행 시점에는 인터프리터와 같이 기계어 코드를 생성하면서 해당 코드가 컴파일 대상이 되면 컴파일하고 그 코드를 캐싱함
* JIT 컴파일은 코드가 실행되는 과정에 실시간으로 일어나며, 전체 코드의 필요한 부분만 변환
* 기계어로 변환된 코드는 캐시에 저장되기 때문에 재사용 시 컴파일을 다시 할 필요가 없다.

### JIT의 동작 방식
* JIT 컴파일러가 컴파일하는 조건은 얼마나 자주 코드가 실행됐는가 이다.
* 일정한 횟수만큼 실행되고 나면 컴파일 임계치에 도달하고 컴파일러는 컴파일하기에 충분한 정보가 쌓였다고 생각한다.
* 임계치는 메서드가 호출 된 횟수, 메서드의 루프를 빠져나오기까지 수행 된 횟수 두 개를 기반으로 함.
* 이 두 수의 합계를 확인하고 메서드가 컴파일 될 자격이 있는지 여부를 결정.
* 자격에 부합하는 경우 메서드는 컴파일 되기 위해 큐에서 대기하며, 이후 메서드들은 컴파일 스레드에 의해 컴파일 됨.
* 아주 오랫동안 돌아가는 루프문의 카운터가 임계치를 넘어가면 해당 루프는 컴파일 대상이 됨.

### GC의 종류
* Serial GC
  > 하나의 CPU로 Young 영역과 Old 영역을 연속적으로 처리하는 방식.
  > GC가 수행될 때 STW(Stop The World)가 발생.
* Parallel GC
  > Parallel GC의 목표는 다른 CPU가 GC의 진행시간 동안 대기 상태로 남아 있는 것을 최소화 하는 것.    
  > Serial GC의 Young 영역에서 진행하는 방식을 병렬로 처리하여 부하를 줄인다.
* Parallel Old GC
  > Parallel GC에서 사용하던 Mark Sweep Compation 대신 개선 버전인 Mark Summary Compaction 알고리즘을 사용.
  > Parallel GC는 Minor GC에 대해서 멀티 스레딩으로 수행하는 것에 반해, Parallel Old GC는 Major GC에 대해서도 멀티 스레딩으로 수행한다.
* Concurrent Mark-Sweep(CMS) GC
  > Application의 Thread와 GC Thread가 동시에 실행되어 STW를 최소화 하는 GC이다.    
  > Parallel GC와 가장 큰 차이점은 Compaction 작업 유무로 구분될 수 있다.    
  > Compaction은 메모리 공간에서 사용하지 않는 빈 공간이 없도록 옮겨서 메모리 분산을 제거하는 작업을 의미.     
  > CMS GC는 Compacton을 지원하지 않는다.
* G1(Garbage First) GC
  > G1 GC는 CMS GC를 대체하기 위해 새롭게 등장하였으며, 대용량의 메모리가 있는 멀티 프로세서 시스템을 위해 제작되었다.    
  > 빠른 처리 속도를 지원하면서 STW를 최소화    
  > CMS GC보다 효율적으로 동시에 Application과 GC를 진행할 수 있고, 메모리 Compaction 과정까지 지원하고 있다.     
  > Java 9 버전부터 기본 GC 방식으로 채택
  
### G1 GC
> G1은 Garbage First의 약어로 Garbage만 있는 Region을 먼저 회수한다고 해서 붙여진 이름     
> 빈 공간 확보를 더 빨리 한다는 것은 조기 승격이나 급격히 할당률이 늘어나는 것을 방지하여 Old Generation을 비교적 한가하게 만들 수 있다
* **장점**
  * 별도의 STW 없이도 여유 메모리 공간을 압축하는 기능을 제공
  * 전체 Old Generation 혹은 Young Generation 통째로 Compaction을 할 필요 없고, 해당 Generation의 일부분 Region에 대해서만 Compaction을 하면 됨
  * Heap 크기가 클수록 잘 동작한다.
  * CMS의 비해 개선된 알고리즘을 사용하고, 처리 속도가 더 빠르다.
  * Garbage로 가득찬 영역을 빠르게 회수하여 빈 공간을 확보하므로 GC 빈도가 줄어든다.
* **단점**
  * 공간 부족 상태를 조심해야 한다. (Minor GC, Major GC 수행하고 나서도 여유 공간이 부족한 경우)
    * 이때는 Full GC가 발생하는데, 이 GC는 Single Thread로 동작.
    * Full GC는 heap 전반적으로 GC가 발생하는 것.
  * 작은 Heap 공간을 가지는 Application에서는 제 성능을 발휘하지 못하고 Full GC가 발생.
  * Humonogous 영역은 제대로 최적화되지 않으므로 해당 영역이 많으면 성능이 떨어짐.
  
### G1 GC의 Heap 구조 
> G1 GC는 기존 힙 구조와 완전히 다른 양상을 띈다.    
> 전통적인 힙 구조는 Young, Old 영역을 명확하게 구분하였지만, G1 GC는 개념적으로 그들이 존재하나 일정 크기의 논리적 단위인 region으로 구분하고 있다.
<img width="300" alt="image" src="https://github.com/elephant97/TIL/assets/82919411/84845a0e-0b7e-4eb0-9c2b-3ea18324f88f">

<br>

* Humonogous: Region 크기의 50%를 초과하는 큰 객체를 저장하기 위한 공간
* Available/Unused: 아직 사용되지 않은 Region

### @Retention
> 어노테이션 라이프 사이클 즉, 어노테이션이 언제까지 살아 남아 있을지를 정하는 것입니다.
* **RetentionPolicy**
  * RetentionPolicy.SOURCE
    > 소스 코드(.java)까지 남아있는다.
      * lombok에서 @Getter @Setter에 해당
      * 컴파일할 때 해당 어노테이션이 사라지는 대신 실제 getter 코드가 바이트 코드로 생성 됨.
  * RetentionPolicy.CLASS
    > 클래스 파일(.class)까지 남아있는다.(=바이트 코드)
      * @NonNull의 경우 Maven / Gradle 로 다운받은 라이브러리와 같이 jar 파일에는 소스가 포함되어 있지 않기 때문에
      * class로 남아있어야 한다(class 파일만 존재하는 라이브러리 같은 경우, 클래스 로딩시 무언가를 하고싶은 경우에 필요)
  * RetentionPolicy.RUNTIME
    > 런타임까지 남아있는다.(=사실상 안 사라진다.)
      * 런타임에 어노테이션 정보를 뽑아 사용 가능하다.
      * Reflection API등을 사용하여 어노테이션 정보를 알 수 가있다.
      * @Controller, @Service, @Autowired등의 어노테이션은 스프링이 올라오는 실행 중인 시점에 컴포넌트 스캔이 가능해야하기 때문에       
        RUNTIME 정책이 필요하다.

### System.out.println이 성능의 저하를 발생시키는 이유는?
* I/O 작업의 오버헤드
  * 해당 메서드는 콘솔에 메세지를 출력하기 위해 I/O작업을 수행하는데, I/O작업은 상대적으로 속도가 느리며 시스템 자원을 많이 소비함
* Synchronization
  * System.out은 Thread safe한 구조로 되어있어 여러 쓰레드가 동시에 해당 메서드를 호출할 시 상호배제를 보장하기 위한 동기화 작업 필요
  * 이로 인한 쓰레드간 경합이 발생하고 성능에 영향을 미칠 수 있음
* 버퍼링 부재
  * System.out은 출력 내용을 버퍼에 쌓아두지 않고 즉시 출력하기 떄문에 작은 메세지를 매번 출력할때마다 I/O 작업이 발생하여 성능 저하를 일으킬 수 있음
  * 대신 버퍼링을 사용하여 여러 메세지를 한번에 출력하도록 개선 가능


### Thread와 Process의 차이
* Thread
  > 프로세스 내에서 실행되는 작은 실행 단위로, 프로세스의 자원을 공유함     
  > 여러 스레드가 하나의 프로세스 내에서 동시에 실행될 수 있으며, 스레드 간에는 프로세스 메모리 공간을 공유함. 
* Process
  > 독립적인 실행 환경을 가진 프로그램의 인스턴스     
  > 각 프로세스는 자체 메모리 공간, 파일 디스크립터, CPU 레지스터 등을 가지며, 서로 영향을 주지 않는다.       
  > 프로세스는 운영체제에서 시스템 리소스를 할당받아 실행 됨
* **생성 및 소멸헤드**
  * Process
    * 프로세스의 생셩 및 소멸에는 상대적으로 큰 오버헤드가 있다. 
    * 새로운 프로세스를 시작하는 데 시간이 오래걸리며, 자원을 할당하고 해제하는 과정이 필요
  * Thread 
    * 쓰레드는 프로세스 내에서 생성 및 소멸이 비교적 빠르며,오버헤드가 적다
* **동시성과 병렬성** 
  * Process
    * 여러 프로세스 간에는 병렬 실행이 가능하지만, 프로세스 간 통신이 복잡하고 오버헤드가 크기 때문에 동시성을 달성하기 어려움
  * Thread 
    * 스레드는 동일한 프로세스 내에서 실행되므로, 공유 메모리를 통해 효율적으로 동시성을 구현할 수 있음.
* **안정성**
  * Process
    * 프로세스는 독립적인 메모리 공간을 가지므로 한 프로세스의 오류가 다른 프로세스에 영향을 미치지 않음
  * Thread
    * 쓰레드는 같은 메모리 공간을 공유하므로, 한 쓰레드의 오류가 다른 쓰레드에 영향을 미칠 수 있음
    * 쓰레드간 동기화를 신경써야 하며, 안정성에 주의해야함

### 세마포어와 뮤텍스의 차이
* 사용 목적
  * Semaphore
    * 세마포어는 동시에 여러 스레드 또는 프로세스가 공유자원에 접근하는 것을 제어하고 조절하기 위해 사용
    * 세마포어는 특정 리소스에 대한 동시 접근을 제어하거나, 제한된 개수의 스레드나 프로세스가      
      특정 작업을 수행하도록 하는 데 유용
  * Mutex
    * 뮤텍스는 상호 배제를 달성하기 위해 사용 됨.
    * 특정 시점에는 하나의 스레드 또는 프로세스만이 공유 자원에 접근할 수 있도록 하는 데 사용 됨.
* 대기 상태 관리
  * Semaphore
    * 세마포어는 쓰레드나 프로세스를 대기 상태로 전환하거나, 대기중인 쓰레드나 프로세스를 꺠우는데 사용 됨
  * Mutex
    * 뮤텍스는 잠긴 상태일때, 뮤텍스를 소유한 쓰레드나 프로세스가 다른 쓰레드나 프로세스가 뮤택스를 사용하려고      
      시도하면 대기하게 됨. 이러한 상황은 뮤택스 대기가 아닌 락 대기로 알려져 있음.
* 컨트롤 유닛
  * Semaphore
    * 세마포어는 정수 값을 가지며, 이 값은 허용되는 스레드 또는 프로세스의 수를 나타냄. 
    * 세마포어 값을 변경하고 조절하여 동시 접근을 제어합니다.
  * Mutex
    *  뮤텍스는 이진(0 또는 1) 값을 가지며, 상태를 "잠금" 또는 "해제"로 나타냄. 
    *  뮤텍스가 잠겨 있으면 하나의 스레드 또는 프로세스만이 자원에 접근할 수 있음.

### Comparable는 어디에 쓰이나?
> comparable 인터페이스를 구현한 객체는 자신과 다른 객체를 비교하고 정렬할 수 있음
* 정렬 알고리즘 사용
  * Comparable인터페이를 구현한 객체는 순서에 따라 정렬 가능
  * 배열 또는 컬렉션을 정렬할 떄 사용할 수 있음
  * Arrays.sort()및 Collections.sort()와 같은 메서드를 사용하여 Comparable을 구현한 객체 정렬 가능
* 검색 알고리즘
  * 이진 검색 알고리즘을 활용하여 정렬된 리스트에서 원하는 항목을 효율적으로 찾을 수 있음
* 우선순위 큐
  * 우선순위 큐와 같은 자료구조에서 우선순위에 따라 요소를 삽입하고 추출하는데 사용
* 커스텀 정렬
  * 객체의 특정 속성을 기준으로 사용자 정의 정렬을 수행할 때 사용
* 데이터 구조와 관련된 다양한 작업
  * 이진트리, 힙 등과 같은 데이터 구조에서 노드 또는 요소를 삽입, 삭제 및 검색하는데 활용 됨

### Comparable과 Comparator의 차이
* Comparable
> 자기 자신과 매개변수 객체를 비교 함
* Comparator
> 두 매개변수 객체를 비교 함

### Atomic Operation이란?
> 컴퓨터 과학에서 여러 단계로 나누어 실행되는 대신, 한번의 연산으로 실행되는 연산을 말함      
> 다중 스레드 또는 다중 프로세스 환경에서 데이터의 일관성과 동시성을 보장하기 위해 중요함
* 원자성(Atomicity)
  * 원자적 연산은 분해되지 않고 하나의 단위로 실행된다.
  * 다른 스레드나 프로세스에서는 실행중인 원자적 연산의 중간 상태를 볼 수 없음
* 일관성(Consistency)
  * 원자적 연산은 시스템의 상태를 일관된 상태로 유지함.
  * 다중 스레드 또는 다중 프로세스 환경에서 실행되더라도 데이터의 일관성 보장
* 고립성(Isolation)
  * 원자적 연산은 다른 연산과 상호 간섭하지 않고 독립적으로 실행 됨
  * 다른 연산에 의해 영향을 받지 않음
* 지속성(Durability)
  * 원자적 연산이 성공하면 해당 연산의 결과는 영구적으로 저장 됨.
  * 시스템이 실패하더라도 데이터의 일관성이 유지 됨.

### Java에서의 Automic Type
> Concurrency API에서 제공함
**처음부터 끝까지 완전히 수행되던가, 아얘 아무것도 수행되지 않아야 하는 Action**
**단위가 분리되면 안되는 연산에 Atomic Operation이 필요**
* 대표적으로 volatile(예약어), synchronization(예약어), Atomic(클래스)이 있다
* Atomic Type은 단일 변수에 대해 Atomic Operation을 지원함
* Wrapping 클래스의 일종으로 참조타입과 원시타입 두 종류 변수에 모두 적용 가능
* 사용 시 내부적으로 Compare-And-Swap(CAS)알고리즘을 사용해 lock 없이 동기화 처리를 할 수 있음
* 변수를 선언할 때 타입을 Atomic 타입으로 선언해 주면 됨
* 연산에서 기대하는 값과 비교하여 업데이트 함

<br>

* 주요 Class
  * AtomicBoolean
  * AtomicInteger
  * AtomicLong
  * AtomicIntegerArray
  * AtomicDoubleArray
* 주요 Method
  * get() 
    > 현재 값을 반환한다.
  * set(newValue) 
    > newValue로 값을 업데이트한다.
  * getAndSet(newValue) 
    > 원자적으로 값을 업데이트하고 원래의 값을 반환한다.
  * compareAndSet(expect, update) 
    > 현재 값이 예상하는 값(=expect)과 동일하다면 값을 update 한 후 true를 반환한다.    
    > 예상하는 값과 같지 않다면 update는 생략하고 false를 반환한다.
  * Number 타입의 경우 값의 연산을 할 수 있도록 addAndGet(delta), getAndAdd(delta), getAndDecrement(), getAndIncrement(), incrementAndGet() 등의 메서드를 추가로 제공.

